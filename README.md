# medical-datasets
I list all the medical data sets I find in my researches.

## IMAGES

* Zhao et al. have released a COVID19-CT dataset, with detailed descriptions. 
You can find it [here](https://github.com/UCSD-AI4H/COVID-CT).

* Prostate cANcer graDe Assessment (PANDA) is a challenge on the Kaggle, so you can find the data and description [here](https://www.kaggle.com/c/prostate-cancer-grade-assessment/overview)

* There are 3 challenges for aneurysm detection, segmentation and rupture risk estimation. You can find the challenge [here](https://cada.grand-challenge.org/Introduction/). Registration may be needed.

* The AutoImplant challenge where a fast and automatic design of cranial implants is highly desired. You can find the challenge information [here](https://autoimplant.grand-challenge.org/). Registration may be needed.

* DFU challenge is a repository of 4500 DFU images for the purpose of supporting research toward more advanced methods of Diabetic Foot Ulcers (DFU) detection. You can access the data [here](https://dfu2020.grand-challenge.org/). Registration may be needed.

* KNee OsteoArthritis Prediction (KNOAP2020) Challenge is about identifying which knees will develop symptomatic radiographic knee osteoarthritis within 6.5 years follow-up. More information is provided [here](https://knoap2020.grand-challenge.org/Home/). Registration may be needed.

* The Learn2reg challenge, which builds on a popular [tutorial](https://learn2reg.github.io) in 2019, will be a simplified challenge design that removes many of the common pitfalls for learning and applying transformations. The data can either be individually or comprehensively addressed by participants and cover both intra- and inter-patient alignment, CT, ultrasound and MRI modalities, neuro-, thorax and abdominal anatomies and the four of the imminent challenges of medical image registration:
  1. learning from small datasets
  2. estimating large deformations
  3. dealing with multi-modal scans
  4. learning from noisy annotations
  
  you can find more information [here](https://learn2reg.grand-challenge.org/).

* The SIIM-ACR Pneumothorax segmentation challenge is about developing an AI algorithm to detect pneumothorax. More info is provided [here](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation).

* The goal of APTOS 2019 Blindness Detection challenge is to gain the ability to automatically screen images for disease and provide information on how severe the condition may be. More info is provided [here](https://www.kaggle.com/c/aptos2019-blindness-detection/)

* Challenge on Liver Ultrasound Tracking. The aim of this challenge is to present the current state-of-the-art in automated tracking of anatomical landmarks in the liver and compare different methods. More info is provided [here](https://clust.ethz.ch/)

* RSNA Intracranial Hemorrhage Detection. The goal of the challenge is to build an algorithm to detect acute intracranial hemorrhage and its subtypes. Click [here](https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/overview?utm_medium=email&utm_source=intercom&utm_campaign=competition-recaps-rsna-2019) for more information.

* The MRNet dataset consists of 1,370 knee MRI exams performed at Stanford University Medical Center. The labels were obtained through manual extraction from clinical reports and the challenge is about classification. [Here](https://stanfordmlgroup.github.io/competitions/mrnet/) you can find more information.

* The aim of Open Knowledge-Based Planning (OpenKBP) Challenge is to advance fair and consistent comparisons of dose prediction methods for knowledge-based planning (KBP). Participants of the challenge will use a large dataset to train, test, and compare their prediction methods, using a set of standardized metrics, with those of other participants. [Here](https://www.aapm.org/GrandChallenge/OpenKBP/) is provided more information.

* The MArkerless Lung Target Tracking CHallenge (MATCH) challenge stands for Markerless Lung Target Tracking Challenge. The aim is to systematically investigate and benchmark the accuracy of various approaches for lung tumour motion tracking during radiation therapy in both a retrospective simulation study (Part A) and a prospective phantom experiment (Part B). [Here](https://www.aapm.org/GrandChallenge/MATCH/) is provided more information.

* Automatic detection of foreign objects on chest X-rays provides a large dataset of chest X-rays with strong annotations of foreign objects, and the competition for automatic detection of foreign objects. More information can be found [here](https://jfhealthcare.github.io/object-CXR/).

* Multi-channel MR Image Reconstruction Challenge (MC-MRRec) challenge has two separate tracks, and teams are free to decide whether to submit to just one track or both; we encourage teams to submit to both tracks. Each track will have a separate ranking.

  1. sampling pattern masks will be provided for R = {5,10} (R is the acceleration factor) and submissions will be evaluated only on the 12-channel test data
  2. sampling pattern masks will be provided for R = {5,10} and submissions will be evaluated for both the 12-channel and 32-channel test data

  The website is [here](https://sites.google.com/view/calgary-campinas-dataset/home/mr-reconstruction-challenge). Registration may be needed.

* MEMENTO Challenge is composed of 4-subchallenges, based on 4 datasets reflecting the same (or similar) underlying biology. You can find more information [here](https://my.vanderbilt.edu/memento/) if you are interested!

* AccelMR 2020 Prediction Challenge invites researchers to define the non-linear mapping between pairs of magnetic resonance images (MRI) acquired at multiple resolutions. [here](https://accelmr.org/about/) is provided more information.


* Skin Lesion Analysis Towards Melanoma Detection challenge is about  classification of dermoscopic images among nine different diagnostic categories. More information is provided [here](https://challenge2019.isic-archive.com/).

* AAPM RT-MAC Challenge is made up of multiple phases:

  1. Phase 1 will conducted via this website in advance of the AAPM meeting. 12 test images will be provided and results will be submitted online. An individual from each of the two top-performing teams will receive a waiver of the meeting registration fee in order to present their methods during the challenge symposium at AAPM.

  2. Phase 2 will be conducted live at the AAPM. A further 10 test images will be provided for evaluation, and participants will have 2 hours to generate results. Participants need not have participated in Phase 1 to be part of Phase 2. Symposium Following Phase 2 a symposium will be held at which the results of both previous phases will be presented.

  3. Phase 3 will be an on-going benchmarking conducted via this website. Both test sets from phase 2 will be included within the on-going assessment.

  You can find more information [here](http://aapmchallenges.cloudapp.net/competitions/34) if you are interested.

* Segmenting and tracking moving cells in time-lapse video sequences is a challenging task. You can find a challenge about this issue [here](http://celltrackingchallenge.net/).

* The 2nd Diabetic Retinopathy – Grading and Image Quality Estimation Challenge is about  evaluation of algorithms for automated fundus image quality estimation and grading of diabetic retinopathy. More information is provided [here](https://isbi.deepdr.org/).

* In the SIIM-ISIC Melanoma Classification challenge you will identify melanoma in images of skin lesions. In particular, you’ll use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists. You can find the challenge [here](https://www.kaggle.com/c/siim-isic-melanoma-classification?utm_medium=email&utm_source=gamma&utm_campaign=siim-email-launch).

* Multi-Centre, Multi-Vendor & Multi-Disease Cardiac Image Segmentation Challenge (M&Ms) aims to contribute to the effort of building generalisable models that can be applied consistently across clinical centres. Furthermore, M&Ms will provide a reference dataset for the community to build and assess future generalisable models in CMR segmentation. You can find more information [here](https://www.ub.edu/mnms/).

* AnDi: The anomalous diffusion challenge aims at bringing together a vibrating and multidisciplinary community of scientists working on this problem. The use of the same reference datasets will allow an unbiased assessment of the performance of published and unpublished methods for characterizing anomalous diffusion from single trajectories. More information can be found [here](https://competitions.codalab.org/competitions/23601#learn_the_details-overview).

* MICCAI 2020: HEad and neCK TumOR segmentation challenge (HECKTOR) will be presented at the 23rd International Conference on Medical Image Computing and Computer Assisted Intervention, October 4th to 8th, 2020. So you have time to follow it [here](https://www.aicrowd.com/challenges/hecktor).

* In MoNuSAC challenge, participants will be provided with H&E stained tissue images of four organs with annotations of multiple cell-types including epithelial cells, lymphocytes, macrophages, and neutrophils. [here](https://monusac-2020.grand-challenge.org/) you can find more information and registration may be needed.

* Endoscopy Computer Vision Challenge (EndoCV2020) includes two sub-challenges where each sub-challenge consists of detection, semantic segmentation and out-of-sample generalization tasks. More information is provided [here](https://endocv.grand-challenge.org/) and registration may be required.

* The main goal of LNDB challenge is the automatic classification of chest CT scans according to the 2017 Fleischner society pulmonary nodule guidelines for patient follow-up recommendation. [here](https://lndb.grand-challenge.org/) you can find more information and registration may be required.

* VerSe`20: Large Scale Vertebrae Segmentation Challenge includes two tasks:
  1. Vertebra Labelling, comprised of localisation and identification of vertebrae.
  2. Vertebra segmentation.
  
  More information is provided [here](https://verse2020.grand-challenge.org/Tasks/) and registration may be required.

* The goal of the PAIP2020 challenge is to evaluate new and existing algorithms for the automated classification of molecular subtypes in colorectal cancer for whole-slide image analyses. You can find more informations [here](https://paip2020.grand-challenge.org/) and registration may be required.

* MICCAI 2020 RibFrac Challenge: Rib Fracture Detection and Classification establishes a large-scale benchmark dataset to automatically detect and classify around 5,000 rib fractures from 660 computed tomography (CT) scans, which consists of 420 training CTs (all with fractures), 80 validation CTs (20 without fractures) and 160 evaluation CTs. Each annotation consists of a pixel-level mask of rib fracture regions (for serving detection), plus a 4-type classification. Both detection and classification tasks are involved in this challenge. An algorithmic challenge for rib fracture detection and classification is the elongated object shape. You can find more information [here](https://ribfrac.grand-challenge.org/). Registration may be required.

* Computed tomography ventilation imaging evaluation 2019 (CTVIE19): An AAPM Grand Challenge is about CTVIE19 and the goal is to determine which CT ventilation imaging algorithms best correlate with reference measures across a range of pulmonary pathologies. More information is available [here](). 

* The main topic of the TN-SCUI2020 challenge is finding  automatic algorithms to accurately classify the thyroid nodules in ultrasound images. More information is provided [here](https://tn-scui2020.grand-challenge.org/).

* 

* 

* 

* 

* 

* 

* 

* 

* 

* 





## Surgical data science

* SurgVisDom - Surgical Visual Domain Adaptation 2020, [here](https://surgvisdom.grand-challenge.org/Home/).

* The [SARAS](www.saras-project.eu) (Smart Autonomous Robotic Assistant Surgeon) is working towards replacing the assistant surgeon. An artificial intelligence based system is required which not only can understand the complete surgical scene but also detect the actions being performed by the main surgeon. This challenge has recorded four sessions of complete prostatectomy procedure performed by expert surgeons on real patients with prostate cancer. Later, expert AI and medical professions annotated these complete surgical procedures for the actions. Hence, each frame is labeled for multiple actions and these actions can have overlapping bounding boxes. You can find more information about this interesting challenge [here](https://saras-esad.grand-challenge.org/).


## Other
*  Radar signatures of human activities includes radar signatures of different indoor human activities performed by different people in different locations. [here](http://researchdata.gla.ac.uk/848/) you can find more information.


## UNDER STURY

* https://paperswithcode.com/area/medical
* https://grand-challenge.org: page 1 is done.
* https://sites.google.com/site/aacruzr/image-datasets
* https://www.cancerimagingarchive.net/
* https://www.acrdsi.org/DSI-Services/Dataset-Directory
* https://radiopaedia.org/articles/imaging-data-sets-artificial-intelligence
* http://www.aylward.org/notes/open-access-medical-image-repositories
* 


